{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# colab не может найти зависимость\n",
    "# !pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "146a72da179bb74f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from os.path import join as pjoin\n",
    "from shutil import rmtree\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from helpy import (\n",
    "    rename_files_in_folder,\n",
    "    rename_files_and_update_annotations,\n",
    "    save_coco_masks,\n",
    "    save_coco_masks_npy,\n",
    "    visualize_npy,\n",
    "    merge_coco_json\n",
    ")\n",
    "\n",
    "from CustomCOCOSegmentation import CustomCOCOSegmentation\n",
    "from train import (\n",
    "    CheckpointSaver,\n",
    "    IoUMetric,\n",
    "    MulticlassCrossEntropyLoss,\n",
    "    MulticlassDiceLoss,\n",
    "    load_checkpoint,\n",
    "    train\n",
    ")\n",
    "\n",
    "from TMJDataset import TMJDataset\n",
    "from Unet.UNet import UNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a114341c01d0f96",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 314159, torch_deterministic: bool = False) -> None:\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(torch_deterministic)\n",
    "\n",
    "\n",
    "seed_everything(42, torch_deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Определяем размер изображения\n",
    "IMAGE_SIZE = 512  # Или любой другой размер\n",
    "\n",
    "# Группировка базовых преобразований\n",
    "basic_transforms = A.Compose([\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),  # Изменение размера\n",
    "    A.PadIfNeeded(min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, p=1.0),  # Добавление паддинга\n",
    "    A.CropNonEmptyMaskIfExists(height=IMAGE_SIZE, width=IMAGE_SIZE),  # Обрезка\n",
    "    A.HorizontalFlip(p=0.5),  # Случайный горизонтальный флип\n",
    "])\n",
    "\n",
    "# Группировка агрессивных преобразований\n",
    "aggressive_transforms = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.AdvancedBlur(p=0.5),  # Размытие\n",
    "        A.GaussNoise(p=0.5),  # Шум Гаусса\n",
    "        A.CLAHE(p=0.5),  # CLAHE\n",
    "    ], p=0.5),  # Применяется с вероятностью 30%\n",
    "    \n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(p=0.5),  # Случайная яркость и контраст\n",
    "        A.RandomGamma(p=0.5),  # Случайная гамма\n",
    "        A.ColorJitter(p=0.5),  # Случайное изменение яркости, контраста и насыщенности\n",
    "    ], p=0.5),  # Применяется с вероятностью 30%\n",
    "    \n",
    "    A.Rotate(limit=20, p=0.5),  # Случайный поворот\n",
    "])\n",
    "\n",
    "# Итоговая трансформация, где сначала применяются базовые, затем агрессивные\n",
    "transforms = A.Compose([\n",
    "    basic_transforms,  # Базовые преобразования\n",
    "    aggressive_transforms,  # Агрессивные преобразования\n",
    "    ToTensorV2(),  # Преобразование в тензор\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38fd2a15157ba16f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_dataset = TMJDataset(\n",
    "    image_dir=\"full_dataset/images\",\n",
    "    mask_dir=\"full_dataset/masks\",\n",
    "    transforms=transforms\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd061a191862dbdf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_dataset.visualize(idx=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5718dfe09d4f2277",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print('Количество изображений в полном датасете:',len(full_dataset))\n",
    "print('Количество изображений в тренировочном датасете:',len(train_dataset))\n",
    "print('Количество изображений в валидационном датасете:',len(val_dataset))\n",
    "print('Количество изображений в тестовом датасете:',len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b6acfd3c226227",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Визуализируем изображение и маску"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5663728965965bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0fa9f0933763051"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CLASSES_NUM = 2\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "BETAS = (0.9, 0.999)\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "EPOCH_NUM = 75\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "TENSORBOARD_DIR = \"tensorboard\"\n",
    "RM_CHECKPOINTS_DIR = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "361f7be95d89900f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(cpu=False, mixed_precision=\"fp16\")\n",
    "model = UNet(n_channels=3, n_classes=CLASSES_NUM, bilinear=False)\n",
    "\n",
    "loss_fn = MulticlassCrossEntropyLoss(ignore_index=255, reduction=\"sum\")\n",
    "metric_fn = IoUMetric(classes_num=CLASSES_NUM, reduction=\"macro\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, betas=BETAS\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=optimizer, step_size=10, gamma=0.85\n",
    ")\n",
    "\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "checkpointer = CheckpointSaver(\n",
    "    accelerator=accelerator,\n",
    "    model=model,\n",
    "    metric_name=\"mIoU\",\n",
    "    save_dir=CHECKPOINTS_DIR,\n",
    "    rm_save_dir=RM_CHECKPOINTS_DIR,\n",
    "    max_history=5,\n",
    "    should_minimize=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60124c0e599b1246",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e885d317fc2963",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# акселерируем\n",
    "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "399a85338fd09875",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_function=loss_fn,\n",
    "    metric_function=metric_fn,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    accelerator=accelerator,\n",
    "    epoch_num=EPOCH_NUM,\n",
    "    checkpointer=checkpointer,\n",
    "    tb_logger=tensorboard_logger,\n",
    "    save_on_val=True,\n",
    "    show_every_x_batch=15,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abf113ff8c8635ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = UNet(n_channels=3, n_classes=CLASSES_NUM,bilinear=False)\n",
    "model = load_checkpoint(\n",
    "    model=model, load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\")\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21b2562d6e2b0c5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "threshold = 0.5  # Порог для бинаризации\n",
    "\n",
    "for sample_idx in range(len(test_dataset)):\n",
    "    # Получаем изображение и истинную маску из тестового датасета\n",
    "    image, target = test_dataset[sample_idx]\n",
    "\n",
    "    # Убедимся, что изображения передаются в нужный формат\n",
    "    image = image.unsqueeze(0).to(DEVICE)  # добавляем размер батча\n",
    "    target = target.unsqueeze(0).to(DEVICE)  # добавляем размер батча\n",
    "\n",
    "    # Получаем предсказания от модели\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "\n",
    "    # Применяем softmax для многоклассовой сегментации (получаем вероятности для каждого класса)\n",
    "    probs = torch.softmax(outputs, dim=1)  # Вероятности для каждого класса\n",
    "\n",
    "    # Проверим размер тензора probs\n",
    "    print(f\"Размер вероятностей: {probs.shape}\")  # Выводим размер тензора для отладки\n",
    "\n",
    "    # Получаем предсказания (класс с максимальной вероятностью для каждого пикселя)\n",
    "    preds = torch.argmax(probs, dim=1).squeeze(0)  # Получаем класс с наибольшей вероятностью для каждого пикселя\n",
    "\n",
    "    # Применяем пороговое значение для каждого класса\n",
    "    binary_preds_class_1 = (probs[0] > threshold).squeeze(0)  # Пороги для первого класса\n",
    "    binary_preds_class_2 = (probs[1] > threshold).squeeze(0)  # Пороги для второго класса\n",
    "\n",
    "    # Выводим метрики\n",
    "    print(metric_fn(outputs.cpu(), target.cpu()))\n",
    "\n",
    "    # Визуализируем результаты\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(12, 18))  # 4 графика, так как два класса\n",
    "\n",
    "    # Визуализируем изображение\n",
    "    ax[0].imshow(image.squeeze(0).cpu().numpy().transpose(1, 2, 0).astype(np.uint8))\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[0].axis('off')  # Убираем оси\n",
    "\n",
    "    # Визуализируем истинную маску\n",
    "    ax[1].imshow(target.squeeze(0).cpu().numpy(), cmap='tab20b')  # Используем cmap для многоклассовой маски\n",
    "    ax[1].set_title(\"Ground Truth Mask\")\n",
    "    ax[1].axis('off')  # Убираем оси\n",
    "\n",
    "    # Визуализируем предсказанную маску для первого класса\n",
    "    ax[2].imshow(binary_preds_class_1.cpu().numpy(), cmap='gray')  # Используем cmap для бинарной маски\n",
    "    ax[2].set_title(\"Predicted Mask Class 1\")\n",
    "    ax[2].axis('off')  # Убираем оси\n",
    "\n",
    "    # Визуализируем предсказанную маску для второго класса\n",
    "    ax[3].imshow(binary_preds_class_2.cpu().numpy(), cmap='gray')  # Используем cmap для бинарной маски\n",
    "    ax[3].set_title(\"Predicted Mask Class 2\")\n",
    "    ax[3].axis('off')  # Убираем оси\n",
    "\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccd9627032441164"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
