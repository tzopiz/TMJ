{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# colab не может найти зависимость\n",
    "# !pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "146a72da179bb74f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from os.path import join as pjoin\n",
    "from shutil import rmtree\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from train import (\n",
    "    CheckpointSaver,\n",
    "    load_checkpoint,\n",
    "    train\n",
    ")\n",
    "\n",
    "from MeanIoU import MeanIoU\n",
    "from DiceLoss import DiceLoss\n",
    "from TMJDataset import TMJDataset\n",
    "from unet import UNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a114341c01d0f96",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 314159, torch_deterministic: bool = False) -> None:\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(torch_deterministic)\n",
    "\n",
    "\n",
    "seed_everything(42, torch_deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Определяем размер изображения\n",
    "IMAGE_SIZE = 512  # Или любой другой размер\n",
    "\n",
    "# Группировка базовых преобразований\n",
    "basic_transforms = A.Compose([\n",
    "    A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),  # Изменение размера\n",
    "    A.PadIfNeeded(min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, p=1.0),  # Добавление паддинга\n",
    "    A.CropNonEmptyMaskIfExists(height=IMAGE_SIZE, width=IMAGE_SIZE),  # Обрезка\n",
    "    A.HorizontalFlip(p=0.5),  # Случайный горизонтальный флип\n",
    "])\n",
    "\n",
    "# Группировка агрессивных преобразований\n",
    "aggressive_transforms = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.AdvancedBlur(p=0.5),  # Размытие\n",
    "        A.GaussNoise(p=0.5),  # Шум Гаусса\n",
    "        A.CLAHE(p=0.5),  # CLAHE\n",
    "    ], p=0.5),  # Применяется с вероятностью 30%\n",
    "    \n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(p=0.5),  # Случайная яркость и контраст\n",
    "        A.RandomGamma(p=0.5),  # Случайная гамма\n",
    "        A.ColorJitter(p=0.5),  # Случайное изменение яркости, контраста и насыщенности\n",
    "    ], p=0.5),  # Применяется с вероятностью 30%\n",
    "    \n",
    "    A.Rotate(limit=20, p=0.5),  # Случайный поворот\n",
    "])\n",
    "\n",
    "# Итоговая трансформация, где сначала применяются базовые, затем агрессивные\n",
    "transforms = A.Compose([\n",
    "    basic_transforms,  # Базовые преобразования\n",
    "    aggressive_transforms,  # Агрессивные преобразования\n",
    "    ToTensorV2(),  # Преобразование в тензор\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38fd2a15157ba16f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_dataset = TMJDataset(\n",
    "    image_dir=\"full_dataset/images\",\n",
    "    mask_dir=\"full_dataset/masks\",\n",
    "    transforms=transforms\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd061a191862dbdf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_dataset.visualize(1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9045851cdeac9bed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print('Количество изображений в полном датасете:',len(full_dataset))\n",
    "print('Количество изображений в тренировочном датасете:',len(train_dataset))\n",
    "print('Количество изображений в валидационном датасете:',len(val_dataset))\n",
    "print('Количество изображений в тестовом датасете:',len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b6acfd3c226227",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0fa9f0933763051"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CLASSES_NUM = 2\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "BETAS = (0.9, 0.999)\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "EPOCH_NUM = 30\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "TENSORBOARD_DIR = \"tensorboard\"\n",
    "RM_CHECKPOINTS_DIR = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "361f7be95d89900f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(cpu=True, mixed_precision=\"fp16\")\n",
    "model = UNet(in_channels=3, out_channels=CLASSES_NUM)\n",
    "\n",
    "loss_fn = DiceLoss()\n",
    "metric_fn = MeanIoU()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, betas=BETAS\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=optimizer, step_size=10, gamma=0.85\n",
    ")\n",
    "\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "checkpointer = CheckpointSaver(\n",
    "    accelerator=accelerator,\n",
    "    model=model,\n",
    "    metric_name=\"mIoU\",\n",
    "    save_dir=CHECKPOINTS_DIR,\n",
    "    rm_save_dir=RM_CHECKPOINTS_DIR,\n",
    "    max_history=5,\n",
    "    should_minimize=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60124c0e599b1246",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e885d317fc2963",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# акселерируем\n",
    "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "399a85338fd09875",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_function=loss_fn,\n",
    "    metric_function=metric_fn,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    accelerator=accelerator,\n",
    "    epoch_num=EPOCH_NUM,\n",
    "    checkpointer=checkpointer,\n",
    "    tb_logger=tensorboard_logger,\n",
    "    save_on_val=True,\n",
    "    show_every_x_batch=15,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abf113ff8c8635ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=CLASSES_NUM)\n",
    "model = load_checkpoint(\n",
    "    model=model, load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\")\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21b2562d6e2b0c5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "thresold = 0.5\n",
    "for sample_idx in range(test_size):\n",
    "    image, target = test_dataset[sample_idx]\n",
    "    outputs = model(image.to(DEVICE))\n",
    "    preds = F.sigmoid(outputs).squeeze(0)\n",
    "    binary_preds = (preds > thresold)\n",
    "    \n",
    "    print(metric_fn(outputs.cpu(), target.unsqueeze(0)))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(9, 18))\n",
    "    ax[0].imshow(image.numpy().transpose(1, 2, 0).astype(np.uint8))\n",
    "    ax[0].set_title(\"Image\") \n",
    "    ax[1].imshow(target.numpy().transpose(1, 2, 0).astype(np.uint8))\n",
    "    ax[1].set_title(\"Mask\")\n",
    "    ax[2].imshow(binary_preds.cpu().numpy()[0])\n",
    "    ax[2].set_title(\"Target\")\n",
    "    plt.show()\n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccd9627032441164"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
